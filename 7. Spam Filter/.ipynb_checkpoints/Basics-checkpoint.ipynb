{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying texts as spam or not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5572 text messages were previously classified as spam or not spam. The dataset was downloaded from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) and contains SMS from three sources:\n",
    "\n",
    "* Grumbletext: 425 spam messages\n",
    "* Random ham messages from NUS SMS Corpus: 3375 non-spam messages\n",
    "* Caroline Tag's PhD Thesis: 450 non-spam messages\n",
    "* SMS Spam Corpus v.0.1 Big: 1002 spam, 322 non-spam messages\n",
    "\n",
    "The purpose of this notebook is to build a spam filter using the naive bayes algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMSSpamCollection', \n",
    "            sep='\\t', header=None, names=['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of non-spam messages: 87.0\n",
      "Percent of spam messages: 13.0\n"
     ]
    }
   ],
   "source": [
    "counted = df['Label'].value_counts()\n",
    "perc_nspam = round(counted[0]/(df['Label'].count()),2)\n",
    "\n",
    "print('Percent of non-spam messages: {0}'.format(perc_nspam*100))\n",
    "print('Percent of spam messages: {0}'.format((1-perc_nspam)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately 87% of the dataset are non-spam and 13% spam messages.\n",
    "\n",
    "The dataset is divided into training (80%) and test(20%) sets. Our goal is to correctly classify as spam or non-spam at least 80% of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df.sample(frac=1, # randomize entire dataset\n",
    "          random_state=1, # seed\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457.6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate what 80% of the number of rows is\n",
    "0.8*df_s.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the first 80% of the randomized dataset is for training\n",
    "train_df = df_s.iloc[:4459,:].reset_index(drop = True)\n",
    "# the rest is for testing\n",
    "test_df = df_s.iloc[4459:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of non-spam messages: 87.0\n",
      "Percent of spam messages: 13.0\n"
     ]
    }
   ],
   "source": [
    "counted = train_df['Label'].value_counts()\n",
    "perc_nspam = round(counted[0]/(train_df['Label'].count()),2)\n",
    "\n",
    "print('Percent of non-spam messages: {0}'.format(perc_nspam*100))\n",
    "print('Percent of spam messages: {0}'.format((1-perc_nspam)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of non-spam messages: 87.0\n",
      "Percent of spam messages: 13.0\n"
     ]
    }
   ],
   "source": [
    "counted = test_df['Label'].value_counts()\n",
    "perc_nspam = round(counted[0]/(test_df['Label'].count()),2)\n",
    "\n",
    "print('Percent of non-spam messages: {0}'.format(perc_nspam*100))\n",
    "print('Percent of spam messages: {0}'.format((1-perc_nspam)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same percentage of spam and non-spam messages were retained when splitting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace everything that is not a letter or number with a space\n",
    "train_df['SMS'] = train_df['SMS'].str.replace('\\W', ' ') \n",
    "# Lower case each letter\n",
    "train_df['SMS'] = train_df['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn each message into a list of words\n",
    "train_df['SMS'] = train_df['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "\n",
    "# extract each word into a new list\n",
    "for cell in train_df['SMS']:\n",
    "    for i in range(len(cell)):\n",
    "        vocabulary.append(cell[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72436\n",
      "7785\n"
     ]
    }
   ],
   "source": [
    "# turn the list into a set, to get rid of duplicates, \n",
    "# and then back into a list\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train_df['SMS']) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where the keys are the unique words from the dataset, and the values are five-thousand 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for index, cell in enumerate(train_df['SMS']):\n",
    "    for word in cell:\n",
    "        # word represents the unique word\n",
    "        # index represents the location of the word in the original dataset\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`enumerate(sequence,start=0)` returns an enumerate object in the form of `[0,word],[1,new_word],[2,newest_word]`.\n",
    "\n",
    "For each word, find the appropriate key then add 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "words_df  = pd.DataFrame(word_counts_per_sms) # turn dictionary into a df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new `words_df` is concatenated with the training set, this way the `Label` and `SMS` columns are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_train_df = pd.concat([train_df, words_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to set up the spam filter, key parameters for Naive Bayes needs to be defined.\n",
    "\n",
    "__Naive Bayes__:\n",
    "\n",
    "We need to calculate the probabilities for both spam and non-spam. The following equations are used:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Non-spam) \\cdot \\prod_{i=1}^{n}P(w_i|Non-spam)\n",
    "\\end{equation}\n",
    "\n",
    "1. The probability that a message is `spam` given the message contains `w_1 ... w_n` (the unique words in our `vocabulary` is proportional to the probability that any message is spam times the probability that `w_i` occurs in the message given the message is spam.\n",
    "2. The same is true of `non-spam` calculations\n",
    "\n",
    "In order to calculate the probability that `word_i` occurs in some message given the message is spam we can use the following equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Non-spam} + \\alpha}{N_{Non-spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "1. The probability that `w_i` occurs in some message given the message is `spam` is equal to the total number of times `w_i` occurrs in all spam messages + alpha. This is then divided by the total number of words in non-spam messages + alpha times the total number of words in our vocabulary.\n",
    "2. The same is true of `non-spam` calculations.\n",
    "\n",
    "__Variable key:__\n",
    "\n",
    "* `spam_df`: a filtered version of `train_df` containing only spam messages\n",
    "* `non_spam_df`: a filtered version of `train_df` containing only non-spam messages\n",
    "* `p_spam`: probability that any message is labeled spam\n",
    "* `p_non_spam`: probability that any message is labeled non_spam\n",
    "* `alpha`: Laplace smoothing parameter\n",
    "* `n_vocab`: number of words in our `vocabulary` list\n",
    "* `n_spam`: total (not unique) number of words in all spam messages\n",
    "* `n_non_spam`: total (not unique) number of words in all non_spam messages\n",
    "* `n_w_spam_dic`: number of times each word occurs in all spam messages\n",
    "* `n_w_non_spam_dic`: number of times each word occurs in all non_spam messages\n",
    "* `p_w_given_spam`: the probability that a word is in a message, given the message is labeled spam\n",
    "* `p_w_given_non_spam`: the probability that a word is in a message, given the message is labeled non-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>dogging</th>\n",
       "      <th>professional</th>\n",
       "      <th>witout</th>\n",
       "      <th>the</th>\n",
       "      <th>trainners</th>\n",
       "      <th>mrt</th>\n",
       "      <th>end</th>\n",
       "      <th>read</th>\n",
       "      <th>...</th>\n",
       "      <th>bein</th>\n",
       "      <th>09061790121</th>\n",
       "      <th>near</th>\n",
       "      <th>waste</th>\n",
       "      <th>zouk</th>\n",
       "      <th>warranty</th>\n",
       "      <th>father</th>\n",
       "      <th>maximize</th>\n",
       "      <th>worrying</th>\n",
       "      <th>goigng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  dogging  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0   \n",
       "2   ham                    [welp, apparently, he, retired]        0   \n",
       "3   ham                                           [havent]        0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...        0   \n",
       "\n",
       "   professional  witout  the  trainners  mrt  end  read  ...  bein  \\\n",
       "0             0       0    1          0    0    0     0  ...     0   \n",
       "1             0       0    0          0    0    0     0  ...     0   \n",
       "2             0       0    0          0    0    0     0  ...     0   \n",
       "3             0       0    0          0    0    0     0  ...     0   \n",
       "4             0       0    0          0    0    0     0  ...     0   \n",
       "\n",
       "   09061790121  near  waste  zouk  warranty  father  maximize  worrying  \\\n",
       "0            0     0      0     0         0       0         0         0   \n",
       "1            0     0      0     0         0       0         0         0   \n",
       "2            0     0      0     0         0       0         0         0   \n",
       "3            0     0      0     0         0       0         0         0   \n",
       "4            0     0      0     0         0       0         0         0   \n",
       "\n",
       "   goigng  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 7787 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = new_train_df[new_train_df['Label'] == 'spam']\n",
    "non_spam_df = new_train_df[new_train_df['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability that any message in our train_df is spam\n",
    "p_spam = (len(spam_df))/len(new_train_df)\n",
    "# The probability that any message in our train_df is non-spam\n",
    "p_non_spam = (len(non_spam_df))/len(new_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the total (not unique) number of words in non_spam messages\n",
    "n_spam = 0\n",
    "# the total (not unique) number of words in spam messages\n",
    "n_non_spam = 0\n",
    "\n",
    "for row in range(len(train_df)):\n",
    "    if train_df.loc[row,'Label'] == 'ham':\n",
    "        n_non_spam += len(train_df.loc[row,'SMS'])\n",
    "    if train_df.loc[row,'Label'] == 'spam':\n",
    "        n_spam += len(train_df.loc[row,'SMS'])\n",
    "\n",
    "# the total number of unique words in all messages\n",
    "n_vocab = len(vocabulary)\n",
    "\n",
    "# alpha for Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of words given label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of the number of times each word\n",
    "# occurs in spam and non-spam messages\n",
    "n_w_spam_dic = {}\n",
    "n_w_non_spam_dic = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    # initialize for number of occurrences list\n",
    "    n_w_spam_dic[word] = 0\n",
    "    n_w_non_spam_dic[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_word_given_key(word, key='spam'):\n",
    "    '''\n",
    "    Finds the number of times the word occurs in the appropriate df,\n",
    "    then appends it to the appropriate dictionary.\n",
    "    '''\n",
    "    if key == 'spam':\n",
    "        series = spam_df['SMS']\n",
    "    else:\n",
    "        series = non_spam_df['SMS']\n",
    "        \n",
    "    n_word = 0\n",
    "    for cell in series:\n",
    "        for msg_word in cell:\n",
    "            if msg_word == word:\n",
    "                n_word += 1\n",
    "    return n_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# For each word in the vocabulary\n",
    "for word in vocabulary:\n",
    "    # Find the number of times it occurs in all messages\n",
    "    n_w_spam_dic[word] = n_word_given_key(word,'spam')\n",
    "    n_w_non_spam_dic[word] = n_word_given_key(word,'non-spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the number of times each word occurs in spam or non-spam messages, we can calculate the probability that each word is in a message given the message is either spam or non-spam\"\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_w_given_spam = {}\n",
    "p_w_given_non_spam = {}\n",
    "\n",
    "# The probability that the word occurs in a message given the message is spam\n",
    "for word in vocabulary:\n",
    "    p_w_given_spam[word] = (n_w_spam_dic[word] + alpha) / (n_spam + (alpha * n_vocab))\n",
    "    p_w_given_non_spam[word] = (n_w_non_spam_dic[word] + alpha) / (n_non_spam + (alpha * n_vocab))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of label given message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the parameters to calculate the probability of some message being spam (or non-spam) given the message's contents.\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_non_spam_given_message = p_non_spam\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_w_given_spam:\n",
    "            p_spam_given_message *= p_w_given_spam[word]\n",
    "        if word in p_w_given_non_spam:\n",
    "            p_non_spam_given_message *= p_w_given_non_spam[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Non-spam|message):', p_non_spam_given_message)\n",
    "\n",
    "    if p_non_spam_given_message > p_spam_given_message:\n",
    "        print('Label: Not spam')\n",
    "    elif p_non_spam_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_spam = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "my_test_non_spam = \"Sounds good, Tom, then see u there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3467710812047665e-25\n",
      "P(Non-spam|message): 1.9339258494902383e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify(my_test_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.43520654878629e-25\n",
      "P(Non-spam|message): 3.6832948885668876e-21\n",
      "Label: Not spam\n"
     ]
    }
   ],
   "source": [
    "classify(my_test_non_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Algorithm on test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify_test(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_non_spam_given_message = p_non_spam\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_w_given_spam:\n",
    "            p_spam_given_message *= p_w_given_spam[word]\n",
    "        if word in p_w_given_non_spam:\n",
    "            p_non_spam_given_message *= p_w_given_non_spam[word]\n",
    "\n",
    "    if p_non_spam_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_non_spam_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted'] = test_df['SMS'].apply(classify_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>But my family not responding for anything. Now...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham             But i haf enuff space got like 4 mb...       ham\n",
       "1  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "2   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "3   ham  All done, all handed in. Don't know if mega sh...       ham\n",
       "4   ham  But my family not responding for anything. Now...       ham"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['eval'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our algorithm correctly classified our messages 98.74% of the time\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_df)\n",
    "\n",
    "for row in test_df.iterrows():\n",
    "    if row[1]['Label'] == row[1]['predicted']:\n",
    "        row[1]['eval'] = 'correct'\n",
    "        correct += 1\n",
    "    if row[1]['Label'] != row[1]['predicted']:\n",
    "        row[1]['eval'] = 'incorrect'\n",
    "accuracy = round((correct/total)*100, 2)\n",
    "print('Our algorithm correctly classified our messages {0}% of the time'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first try at the algorithm had an accuracy rate of 12.49%. This was because `classify_test` returned `\"Not Spam\"` instead of `\"ham\"`. Because of this error, the `Label` column never equaled the `predicted` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message from Dataquest\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 98.74% on the test set, which is an excellent result. We initially aimed for an accuracy of over 80%, but we managed to do way better than that.\n",
    "\n",
    "If you want to keep working on this project, here's a few next steps you can take:\n",
    "\n",
    "* Isolate the 14 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusions.\n",
    "* Make the filtering process more complex by making the algorithm sensitive to letter case.\n",
    "* Get the project portfolio-ready by using a few tips from our style guide for data science projects.\n",
    "\n",
    "Congratulations, this is the end of the Conditional Probability course! We've come a long way and learned how to:\n",
    "\n",
    "* Assign probabilities to events based on certain conditions by using conditional probability rules.\n",
    "* Assign probabilities to events based on whether they are in relationship of statistical independence or not with other events.\n",
    "* Assign probabilities to events based on prior knowledge by using Bayes' theorem.\n",
    "* Create a spam filter for SMS messages using the multinomial Naive Bayes algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "113  spam  Not heard from U4 a while. Call me now am here...   \n",
       "134  spam  More people are dogging in your area now. Call...   \n",
       "151   ham                  Unlimited texts. Limited minutes.   \n",
       "158   ham                                       26th OF JULY   \n",
       "283   ham                             Nokia phone is lovly..   \n",
       "292   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "301   ham                   No calls..messages..missed calls   \n",
       "318   ham  We have sent JD for Customer Service cum Accou...   \n",
       "503  spam  Oh my god! I've found your number again! I'm s...   \n",
       "545  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "740  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "875  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "884  spam                                      2/2 146tf150p   \n",
       "952  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                      predicted       eval  \n",
       "113                         ham  incorrect  \n",
       "134                         ham  incorrect  \n",
       "151                        spam  incorrect  \n",
       "158                        spam  incorrect  \n",
       "283                        spam  incorrect  \n",
       "292  needs human classification  incorrect  \n",
       "301                        spam  incorrect  \n",
       "318                        spam  incorrect  \n",
       "503                         ham  incorrect  \n",
       "545                         ham  incorrect  \n",
       "740                         ham  incorrect  \n",
       "875                         ham  incorrect  \n",
       "884                         ham  incorrect  \n",
       "952                         ham  incorrect  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['eval'] == 'incorrect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
